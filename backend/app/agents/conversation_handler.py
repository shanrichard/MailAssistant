"""
ConversationHandler Agent - åŸºäºLangGraphçš„å¯¹è¯å¤„ç†ä»£ç†
"""
from typing import List, Dict, Any, Optional, Annotated, TypedDict, Sequence
from datetime import datetime, timezone
import uuid
import json
from threading import Lock
import asyncio

from langchain.tools import Tool
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, BaseMessage
from langgraph.prebuilt import create_react_agent
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.graph.message import add_messages

from .base_agent import StatefulAgent
from .conversation_tools import create_conversation_tools
from ..core.config import settings
from ..core.logging import get_logger
from ..core.cache import CheckpointerCache
from ..core.errors import AppError, ErrorCategory, translate_error
from ..core.retry import with_retry, CONVERSATION_RETRY_POLICY
from ..models.conversation import ConversationMessage
from ..utils.chunk_accumulator import ChunkAccumulator

logger = get_logger(__name__)

class AgentState(TypedDict):
    """AgentçŠ¶æ€å®šä¹‰"""
    messages: Annotated[Sequence[BaseMessage], add_messages]
    user_id: str
    session_id: str

class ConversationHandler(StatefulAgent):
    """å¯¹è¯å¤„ç†Agent - åŸºäºLangGraphï¼Œæ”¯æŒæµå¼å“åº”å’Œå·¥å…·è°ƒç”¨å¯è§†åŒ–"""
    
    # ç±»çº§åˆ«ç¼“å­˜LLMå®ä¾‹ï¼Œé¿å…é‡å¤åˆå§‹åŒ–
    # ä½¿ç”¨ (provider, model, temperature) ä½œä¸ºç¼“å­˜é”®
    _llm_cache = {}
    _cache_lock = Lock()  # çº¿ç¨‹å®‰å…¨çš„ç¼“å­˜è®¿é—®é”
    
    # ä½¿ç”¨TTLç¼“å­˜æ›¿ä»£å¼±å¼•ç”¨å­—å…¸ï¼Œè§£å†³ç«æ€æ¡ä»¶é—®é¢˜
    _checkpointer_cache = CheckpointerCache(max_size=1000, ttl_hours=24)
    
    def __init__(self, user_id: str, db_session, user=None):
        """åˆå§‹åŒ–ConversationHandler"""
        super().__init__(user_id, db_session, user)
        
        # åˆ›å»ºLangGraph agentï¼Œä½¿ç”¨æ›´ç²¾ç¡®çš„ç¼“å­˜é”®
        cache_key = (
            settings.llm.default_provider,
            self._get_default_model(),
            self._get_temperature()
        )
        
        # çº¿ç¨‹å®‰å…¨çš„ç¼“å­˜è®¿é—®
        with self._cache_lock:
            if cache_key not in self._llm_cache:
                self._llm_cache[cache_key] = self.llm
            
        # è·å– checkpointer
        self.checkpointer = self._get_checkpointer()
        
        # åˆ›å»º agentï¼Œä½¿ç”¨ prompt å‚æ•°ï¼ˆLangGraph 0.5.3 æ¨èï¼‰
        self.graph_agent = create_react_agent(
            model=self._llm_cache[cache_key],
            tools=self.tools,
            prompt=self._build_prompt,
            checkpointer=self.checkpointer
        )
    
    def _wrap_tool_with_error_handling(self, tool: Tool) -> Tool:
        """åŒ…è£…å·¥å…·ï¼Œæ·»åŠ ç»Ÿä¸€çš„é”™è¯¯å¤„ç†"""
        original_func = tool.func
        original_afunc = getattr(tool, 'afunc', None)
        
        def sync_wrapper(*args, **kwargs):
            try:
                return original_func(*args, **kwargs)
            except Exception as e:
                logger.error(f"Tool {tool.name} failed", 
                           tool_name=tool.name,
                           error=str(e),
                           user_id=self.user_id)
                return {
                    "error": str(e),
                    "error_type": type(e).__name__,
                    "tool": tool.name,
                    "success": False,
                    "message": self._get_user_friendly_error_message(e)
                }
        
        async def async_wrapper(*args, **kwargs):
            try:
                if original_afunc:
                    return await original_afunc(*args, **kwargs)
                else:
                    # åœ¨å¼‚æ­¥ä¸Šä¸‹æ–‡ä¸­è¿è¡ŒåŒæ­¥å‡½æ•°
                    loop = asyncio.get_event_loop()
                    return await loop.run_in_executor(None, original_func, *args, **kwargs)
            except Exception as e:
                logger.error(f"Tool {tool.name} failed (async)", 
                           tool_name=tool.name,
                           error=str(e),
                           user_id=self.user_id)
                return {
                    "error": str(e),
                    "error_type": type(e).__name__,
                    "tool": tool.name,
                    "success": False,
                    "message": self._get_user_friendly_error_message(e)
                }
        
        # åˆ›å»ºæ–°çš„å·¥å…·å®ä¾‹ï¼Œä¿ç•™åŸæœ‰å±æ€§
        return Tool(
            name=tool.name,
            description=tool.description,
            func=sync_wrapper,
            afunc=async_wrapper,
            return_direct=tool.return_direct,
            args_schema=tool.args_schema
        )
    
    def _get_user_friendly_error_message(self, error: Exception) -> str:
        """å°†æŠ€æœ¯é”™è¯¯è½¬æ¢ä¸ºç”¨æˆ·å‹å¥½çš„æ¶ˆæ¯"""
        error_messages = {
            "ConnectionError": "è¿æ¥æœåŠ¡å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•",
            "TimeoutError": "æ“ä½œè¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•",
            "ValueError": "è¾“å…¥å‚æ•°æœ‰è¯¯ï¼Œè¯·æ£€æŸ¥åé‡è¯•",
            "PermissionError": "æƒé™ä¸è¶³ï¼Œæ— æ³•æ‰§è¡Œæ­¤æ“ä½œ"
        }
        
        error_type = type(error).__name__
        return error_messages.get(error_type, f"æ“ä½œå¤±è´¥: {str(error)}")
    
    def _create_tools(self) -> List[Tool]:
        """åˆ›å»ºå¯¹è¯å¤„ç†å·¥å…·é›†ï¼Œåº”ç”¨ç»Ÿä¸€çš„é”™è¯¯å¤„ç†"""
        user_context = {
            "user_id": self.user_id,
            "db_session": self.db,
            "user": self.user
        }
        
        # è·å–åŸå§‹å·¥å…·åˆ—è¡¨
        raw_tools = create_conversation_tools(self.user_id, self.db, user_context)
        
        # ä¸ºæ¯ä¸ªå·¥å…·åº”ç”¨é”™è¯¯å¤„ç†åŒ…è£…
        wrapped_tools = []
        for tool in raw_tools:
            wrapped_tool = self._wrap_tool_with_error_handling(tool)
            wrapped_tools.append(wrapped_tool)
            logger.debug(f"Wrapped tool: {tool.name}", user_id=self.user_id)
        
        return wrapped_tools
    
    def _get_default_model(self) -> str:
        """è·å–é»˜è®¤æ¨¡å‹"""
        return settings.agents.conversation_handler_default_model
    
    def _get_temperature(self) -> float:
        """è·å–æ¸©åº¦å‚æ•°"""
        return settings.agents.conversation_handler_temperature
    
    @with_retry(CONVERSATION_RETRY_POLICY)
    def _get_checkpointer(self):
        """æ ¹æ®ç­–ç•¥è·å– checkpointer - é»˜è®¤ä½¿ç”¨ per_user ç­–ç•¥ï¼Œå¸¦é‡è¯•æœºåˆ¶"""
        # é»˜è®¤ä½¿ç”¨ per_user ç­–ç•¥ï¼Œæ¯ä¸ªç”¨æˆ·å…±äº«ä¸€ä¸ª checkpointer
        checkpointer_key = f"user_{self.user_id}"
        
        # ä½¿ç”¨æ–°çš„TTLç¼“å­˜ï¼Œè‡ªåŠ¨å¤„ç†çº¿ç¨‹å®‰å…¨å’Œè¿‡æœŸæ¸…ç†
        return self._checkpointer_cache.get_or_create(
            checkpointer_key,
            lambda: InMemorySaver()
        )
    
    def _build_prompt(self, state: Dict, config: Dict) -> List[BaseMessage]:
        """æ„å»ºåŒ…å«ç³»ç»Ÿæç¤ºçš„æ¶ˆæ¯åˆ—è¡¨"""
        system_prompt = self._build_system_prompt_for_graph()
        messages = state.get("messages", [])
        
        # åº”ç”¨æ¶ˆæ¯è£å‰ªï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if settings.agents.message_pruning_enabled:
            messages = self._prune_messages(messages)
        
        return [SystemMessage(content=system_prompt)] + messages
    
    def _prune_messages(self, messages: List[BaseMessage]) -> List[BaseMessage]:
        """è£å‰ªæ¶ˆæ¯ä»¥é˜²æ­¢è¶…è¿‡é™åˆ¶"""
        if settings.agents.pruning_strategy == "count":
            return self._prune_by_count(messages)
        elif settings.agents.pruning_strategy == "tokens":
            return self._prune_by_tokens(messages)
        else:
            return messages
    
    def _prune_by_count(self, messages: List[BaseMessage]) -> List[BaseMessage]:
        """åŸºäºæ¶ˆæ¯æ•°é‡çš„è£å‰ª"""
        max_count = settings.agents.max_messages_count
        
        if len(messages) <= max_count:
            return messages
        
        # ä¿ç•™æœ€è¿‘çš„ N æ¡æ¶ˆæ¯
        return messages[-max_count:]
    
    def _prune_by_tokens(self, messages: List[BaseMessage]) -> List[BaseMessage]:
        """åŸºäº token æ•°é‡çš„æ™ºèƒ½è£å‰ª"""
        max_tokens = settings.agents.max_tokens_count
        
        # ç®€åŒ–ç‰ˆå®ç°ï¼šåŸºäºå­—ç¬¦æ•°ä¼°ç®— (çº¦4ä¸ªå­—ç¬¦ = 1ä¸ªtoken)
        # ç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨ tiktoken è¿›è¡Œç²¾ç¡®è®¡ç®—
        total_chars = 0
        result = []
        
        # ä»åå¾€å‰éå†ï¼Œä¿ç•™æœ€æ–°çš„æ¶ˆæ¯
        for msg in reversed(messages):
            msg_chars = len(msg.content)
            estimated_tokens = msg_chars // 4
            
            if total_chars + msg_chars > max_tokens * 4:
                break
            
            result.insert(0, msg)
            total_chars += msg_chars
        
        return result
    
    def _build_system_prompt_for_graph(self) -> str:
        """æ„å»ºLangGraphä½¿ç”¨çš„ç³»ç»Ÿprompt"""
        return """ä½ æ˜¯ç”¨æˆ·çš„è´´å¿ƒé‚®ä»¶ç®¡å®¶ï¼Œè´Ÿè´£ç†è§£ç”¨æˆ·éœ€æ±‚å¹¶åè°ƒå„ç§é‚®ä»¶ç®¡ç†ä»»åŠ¡ã€‚ä½ çš„ä¸“ä¸šé¢†åŸŸåŒ…æ‹¬ï¼š

1. è‡ªç„¶è¯­è¨€ç†è§£å’Œæ„å›¾è¯†åˆ«
2. ä»»åŠ¡è°ƒåº¦å’Œå·¥ä½œæµç®¡ç†
3. ç”¨æˆ·åå¥½å­¦ä¹ å’Œæ›´æ–°
4. é‚®ä»¶æœç´¢å’Œå†å²æŸ¥è¯¢
5. æ‰¹é‡æ“ä½œå’Œæ™ºèƒ½å»ºè®®
6. å®æ—¶çŠ¶æ€åé¦ˆå’Œè¿›åº¦è·Ÿè¸ª

## é‡è¦ï¼šè¾“å‡ºæ ¼å¼è¦æ±‚

**ä½ å¿…é¡»ä½¿ç”¨ Markdown æ ¼å¼æ¥ç»„ç»‡æ‰€æœ‰å›ç­”**ï¼Œè¿™æ ·å¯ä»¥è®©ä¿¡æ¯æ›´æ¸…æ™°ã€æ›´æ˜“è¯»ã€‚è¯·éµå¾ªä»¥ä¸‹æ ¼å¼åŒ–åŸåˆ™ï¼š

- ä½¿ç”¨ **ç²—ä½“** æ ‡è®°é‡è¦ä¿¡æ¯å’Œå…³é”®è¯
- ä½¿ç”¨æ ‡é¢˜ï¼ˆ## æˆ– ###ï¼‰æ¥ç»„ç»‡å†…å®¹ç»“æ„
- ä½¿ç”¨åˆ—è¡¨ï¼ˆ- æˆ– 1. 2. 3.ï¼‰å±•ç¤ºå¤šä¸ªé¡¹ç›®
- ä½¿ç”¨ `è¡Œå†…ä»£ç ` æ ‡è®°é‚®ä»¶åœ°å€ã€æ—¶é—´ç­‰å…·ä½“ä¿¡æ¯
- ä½¿ç”¨å¼•ç”¨ï¼ˆ>ï¼‰æ¥çªå‡ºé‡è¦æç¤ºæˆ–æ€»ç»“
- ä½¿ç”¨è¡¨æ ¼å±•ç¤ºå¯¹æ¯”ä¿¡æ¯ï¼ˆå¦‚æœ‰éœ€è¦ï¼‰
- ä½¿ç”¨åˆ†éš”çº¿ï¼ˆ---ï¼‰åŒºåˆ†ä¸åŒéƒ¨åˆ†

### Markdown ç¤ºä¾‹ï¼š
```
## ğŸ“§ é‚®ä»¶æœç´¢ç»“æœ

æ‰¾åˆ° **3 å°** ç¬¦åˆæ¡ä»¶çš„é‚®ä»¶ï¼š

### é‡è¦é‚®ä»¶
1. **å¼ ä¸‰** - `2024-01-20 14:30`
   > å…³äºé¡¹ç›®è¿›åº¦çš„é‡è¦æ›´æ–°

2. **æå››** - `2024-01-20 10:15`  
   > ä¼šè®®å®‰æ’ç¡®è®¤

### æ™®é€šé‚®ä»¶
- ç³»ç»Ÿé€šçŸ¥ - `2024-01-20 09:00`

---
ğŸ’¡ **å»ºè®®**ï¼šæ‚¨æœ‰ 2 å°é‡è¦é‚®ä»¶éœ€è¦åŠæ—¶å¤„ç†ã€‚
```

é‚®ä»¶æœç´¢æŒ‡å¯¼åŸåˆ™ï¼š

1. æ—¶é—´ç›¸å…³æŸ¥è¯¢ï¼š
   - "æœ€è¿‘"ã€"è¿™å‡ å¤©" â†’ ä½¿ç”¨ days_back=3
   - "ä»Šå¤©" â†’ ä½¿ç”¨ days_back=1
   - "æœ¬å‘¨"ã€"è¿™å‘¨" â†’ ä½¿ç”¨ days_back=7
   - "ä¸Šå‘¨" â†’ ä½¿ç”¨ days_back=14
   - "æœ¬æœˆ"ã€"è¿™ä¸ªæœˆ" â†’ ä½¿ç”¨ days_back=30

2. å‘ä»¶äººç›¸å…³æŸ¥è¯¢ï¼š
   é‡è¦ï¼šæ•°æ®åº“ä¸­ sender å­—æ®µå­˜å‚¨çš„æ˜¯å®Œæ•´æ ¼å¼ï¼Œä¾‹å¦‚ï¼š
   - "Google <no-reply@accounts.google.com>"
   - "å¼ ä¸‰ <zhangsan@example.com>"
   - "Microsoft å¸æˆ·å›¢é˜Ÿ <account-security-noreply@accountprotection.microsoft.com>"
   - "support@alphavantage.co"ï¼ˆæœ‰äº›åªæœ‰é‚®ç®±åœ°å€ï¼‰
   
   ä½¿ç”¨ sender å‚æ•°çš„ç¤ºä¾‹ï¼š
   - "å¼ ä¸‰å‘çš„é‚®ä»¶" â†’ ä½¿ç”¨ sender="å¼ ä¸‰"
   - "googleçš„é‚®ä»¶" â†’ ä½¿ç”¨ sender="google"ï¼ˆä¼šåŒ¹é… "Google <...>"ã€"googlecloud@google.com" ç­‰ï¼‰
   - "å¾®è½¯çš„é‚®ä»¶" â†’ ä½¿ç”¨ sender="å¾®è½¯" æˆ– sender="microsoft"
   - "@gmail.comçš„é‚®ä»¶" â†’ ä½¿ç”¨ sender="gmail.com"
   - "æœ€è¿‘æœ‰ä»€ä¹ˆäººç»™æˆ‘å‘é‚®ä»¶" â†’ ä»…ä½¿ç”¨ days_backï¼Œä¸è®¾ç½® senderï¼ŒæŸ¥çœ‹ sender_summary

   sender å‚æ•°ç‰¹æ€§ï¼š
   - éƒ¨åˆ†åŒ¹é…ï¼šè¾“å…¥çš„æ–‡æœ¬ä¼šåœ¨æ•´ä¸ª sender å­—æ®µä¸­æœç´¢
   - å¤§å°å†™ä¸æ•æ„Ÿï¼šgoogle èƒ½åŒ¹é… Googleï¼Œmicrosoft èƒ½åŒ¹é… Microsoft
   - å¯ä»¥æœç´¢ï¼šå§“åï¼ˆå¼ ä¸‰ï¼‰ã€å…¬å¸åï¼ˆGoogleï¼‰ã€é‚®ç®±åœ°å€ï¼ˆgmail.comï¼‰ã€é‚®ç®±ç”¨æˆ·åï¼ˆno-replyï¼‰

3. çŠ¶æ€ç›¸å…³æŸ¥è¯¢ï¼š
   - "æœªè¯»é‚®ä»¶" â†’ ä½¿ç”¨ is_read=False
   - "å·²è¯»é‚®ä»¶" â†’ ä½¿ç”¨ is_read=True
   - "æœ‰é™„ä»¶çš„é‚®ä»¶" â†’ ä½¿ç”¨ has_attachments=True

5. ç»„åˆæŸ¥è¯¢ç¤ºä¾‹ï¼š
   - "å¼ ä¸‰æœ€è¿‘å‘çš„é‡è¦é‚®ä»¶" â†’ sender="å¼ ä¸‰", days_back=3ï¼Œç„¶åæ ¹æ®ç”¨æˆ·åå¥½åˆ†æç»“æœ
   - "æœ¬å‘¨çš„æœªè¯»é‚®ä»¶" â†’ days_back=7, is_read=False
   - "æœ€è¿‘æœ‰ä»€ä¹ˆäººç»™æˆ‘å‘é‚®ä»¶" â†’ days_back=3, ä¸è®¾ç½®å…¶ä»–å‚æ•°ï¼ŒæŸ¥çœ‹sender_summaryç»Ÿè®¡

æœç´¢æ— ç»“æœæ—¶çš„å¤„ç†ï¼š
å½“é‚®ä»¶æœç´¢è¿”å›0æ¡ç»“æœæ—¶ï¼Œè¯·ï¼š
1. å‘ŠçŸ¥ç”¨æˆ·æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„é‚®ä»¶
2. é‡è¦ï¼šæŸ¥çœ‹è¿”å›æ•°æ®ä¸­çš„ sender_summary å­—æ®µï¼Œå®ƒåŒ…å«æœ€è¿‘é‚®ä»¶çš„å‘ä»¶äººç»Ÿè®¡
3. å‘ç”¨æˆ·å±•ç¤º sender_summary ä¸­çš„å‰å‡ ä¸ªå‘ä»¶äººï¼Œè®©ç”¨æˆ·äº†è§£å®é™…çš„å‘ä»¶äººæ ¼å¼
4. å»ºè®®ç”¨æˆ·ï¼š
   - å¦‚æœæœç´¢ "Microsoft"ï¼Œå¯ä»¥è¯•è¯• "å¾®è½¯" æˆ– "microsoft"
   - å¦‚æœæœç´¢å…¬å¸åæ²¡ç»“æœï¼Œå¯ä»¥è¯•è¯•åŸŸåå¦‚ "microsoft.com"
   - æŸ¥çœ‹ sender_summary ä¸­çš„å‘ä»¶äººï¼Œé€‰æ‹©æ­£ç¡®çš„å…³é”®è¯é‡è¯•
   - ä½¿ç”¨ query å‚æ•°è¿›è¡Œå…¨æ–‡æœç´¢

äº¤äº’åŸåˆ™ï¼š
- ä»¥å‹å¥½ã€ä¸“ä¸šçš„æ–¹å¼ä¸ç”¨æˆ·äº¤æµ
- ä¸»åŠ¨ç†è§£ç”¨æˆ·çš„éšå«éœ€æ±‚
- æä¾›ä¸ªæ€§åŒ–çš„å»ºè®®å’Œè§£å†³æ–¹æ¡ˆ
- åŠæ—¶åé¦ˆä»»åŠ¡æ‰§è¡ŒçŠ¶æ€
- å­¦ä¹ ç”¨æˆ·ä¹ æƒ¯å¹¶ä¼˜åŒ–æœåŠ¡ä½“éªŒ
- åœ¨ä¸ç¡®å®šæ—¶ä¸»åŠ¨è¯¢é—®æ¾„æ¸…

å¯ç”¨å·¥å…·è¯´æ˜ï¼š
- search_email_history: æœç´¢å†å²é‚®ä»¶
  é‡è¦ï¼šå¿…é¡»ä½¿ç”¨å…³é”®å­—å‚æ•°è°ƒç”¨ï¼Œä¾‹å¦‚ï¼š
  search_email_history(days_back=3, sender="google")
  search_email_history(query="ä¼šè®®", is_read=False)
  ä¸è¦ä½¿ç”¨ä½ç½®å‚æ•°å¦‚ search_email_history(3, "google")
- read_daily_report: è¯»å–é‚®ä»¶æ—¥æŠ¥
- bulk_mark_read: æ‰¹é‡æ ‡è®°é‚®ä»¶ä¸ºå·²è¯»
- update_user_preferences: æ›´æ–°ç”¨æˆ·åå¥½
- trigger_email_processor: è§¦å‘é‚®ä»¶å¤„ç†ä»»åŠ¡
- get_task_status: æŸ¥è¯¢ä»»åŠ¡æ‰§è¡ŒçŠ¶æ€

å¸¸è§ç”¨æˆ·éœ€æ±‚å¤„ç†ï¼š
- "å¸®æˆ‘åˆ†æä»Šå¤©çš„é‚®ä»¶" â†’ ä½¿ç”¨ trigger_email_processor(action="generate_daily_report")
- "æŠŠå¹¿å‘Šé‚®ä»¶éƒ½æ ‡è®°ä¸ºå·²è¯»" â†’ ä½¿ç”¨ bulk_mark_read(criteria="å¹¿å‘Šé‚®ä»¶")
- "æˆ‘è§‰å¾—XXç±»é‚®ä»¶å¾ˆé‡è¦" â†’ ä½¿ç”¨ update_user_preferences(preference_description="XXç±»é‚®ä»¶å¾ˆé‡è¦")
- "å¸®æˆ‘æ‰¾googleçš„é‚®ä»¶" â†’ ä½¿ç”¨ search_email_history(sender="google")
- "æœ€è¿‘3å¤©çš„é‚®ä»¶" â†’ ä½¿ç”¨ search_email_history(days_back=3)
- "æœ€è¿‘3å¤©googleçš„é‚®ä»¶" â†’ ä½¿ç”¨ search_email_history(days_back=3, sender="google")
- "ç°åœ¨çš„ä»»åŠ¡è¿›å±•å¦‚ä½•" â†’ ä½¿ç”¨ get_task_status(task_type="all")

è¯·æ ¹æ®ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€è¯·æ±‚ï¼Œæ™ºèƒ½é€‰æ‹©åˆé€‚çš„å·¥å…·ç»„åˆæ¥å®Œæˆä»»åŠ¡ã€‚è®°ä½è¦ä¿æŒå¯¹è¯çš„è¿è´¯æ€§å’Œä¸Šä¸‹æ–‡æ„ŸçŸ¥ï¼Œå¹¶å§‹ç»ˆä½¿ç”¨ Markdown æ ¼å¼è¾“å‡ºã€‚"""
    
    async def stream_response(self, message: str, session_id: str):
        """æµå¼ä¼ è¾“å“åº”ï¼ŒåŒ…å«å·¥å…·è°ƒç”¨ä¿¡æ¯"""
        try:
            # æ„å»ºè¾“å…¥çŠ¶æ€ï¼ˆæ— éœ€æ‰‹åŠ¨åŠ è½½å†å²ï¼Œcheckpointerä¼šè‡ªåŠ¨ç®¡ç†ï¼‰
            input_state = {
                "messages": [HumanMessage(content=message)],
                "user_id": self.user_id,
                "session_id": session_id
            }
            
            # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°æ•°æ®åº“ï¼ˆç”¨äºå‰ç«¯å±•ç¤ºï¼‰
            user_msg = ConversationMessage(
                user_id=self.user_id,
                session_id=session_id,
                role="user",
                content=message,
                message_type="user_message"
            )
            self.db.add(user_msg)
            self.db.commit()
            
            # ä½¿ç”¨æ–°çš„ astream APIï¼ˆåˆ‡æ¢åˆ°messagesæ¨¡å¼ä»¥è·å–tool_call_chunksï¼‰
            response_id = str(uuid.uuid4())
            config = {"configurable": {"thread_id": f"{self.user_id}_{session_id}"}}
            
            # åˆå§‹åŒ–å·¥å…·è°ƒç”¨çŠ¶æ€è·Ÿè¸ª
            if not hasattr(self, '_active_tool_calls'):
                self._active_tool_calls = {}
            
            # åˆå§‹åŒ– chunk ç´¯ç§¯å™¨
            accumulator = ChunkAccumulator(
                min_chunk_size=settings.chunk_min_size,
                max_wait_time=settings.chunk_max_wait,
                delimiter_pattern=settings.chunk_delimiter_pattern
            )
            accumulated_content = ""  # ç”¨äºæ•°æ®åº“å†™å…¥
            
            async for chunk, metadata in self.graph_agent.astream(
                input_state,
                config=config,
                stream_mode="messages"  # åˆ‡æ¢åˆ°messagesæ¨¡å¼ä»¥è·å–tool_call_chunks
            ):
                # ğŸ¯ å¤„ç†tool_call_chunksï¼ˆLangGraphå·¥å…·è°ƒç”¨æµï¼‰
                if hasattr(chunk, 'tool_call_chunks') and chunk.tool_call_chunks:
                    for tool_chunk in chunk.tool_call_chunks:
                        async for event in self._handle_tool_call_chunk(tool_chunk):
                            yield event
                
                # å¤„ç†AIå“åº”å†…å®¹
                if hasattr(chunk, 'content') and chunk.content:
                    # ğŸ” æ£€æŸ¥æ˜¯å¦æ˜¯å·¥å…·æ‰§è¡Œç»“æœ
                    tool_result_event = self._extract_tool_result_from_content(chunk.content)
                    if tool_result_event:
                        # è¿™æ˜¯å·¥å…·æ‰§è¡Œç»“æœï¼Œå‘é€å·¥å…·ç»“æœäº‹ä»¶è€Œä¸æ˜¯æ™®é€šå“åº”
                        yield tool_result_event
                    else:
                        # ä½¿ç”¨ç´¯ç§¯å™¨å¤„ç†æ™®é€šAIå“åº”å†…å®¹
                        emit_content = accumulator.add(chunk.content)
                        accumulated_content += chunk.content
                        
                        if emit_content:
                            yield {
                                "type": "agent_response_chunk",
                                "content": emit_content,
                                "timestamp": datetime.now(timezone.utc).isoformat(),
                                "id": response_id
                            }
                
                # ğŸ—‘ï¸ ç§»é™¤æ‰€æœ‰åŸºäºé”™è¯¯å‡è®¾çš„å·¥å…·è°ƒç”¨å¤„ç†ä»£ç 
                # ç°åœ¨ä½¿ç”¨æ­£ç¡®çš„tool_call_chunkså¤„ç†æœºåˆ¶
            
            # å‘é€å‰©ä½™å†…å®¹
            final_content = accumulator.flush()
            if final_content:
                yield {
                    "type": "agent_response_chunk",
                    "content": final_content,
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "id": response_id
                }
            
            # ä¸€æ¬¡æ€§å†™å…¥å®Œæ•´æ¶ˆæ¯åˆ°æ•°æ®åº“
            if accumulated_content:
                ai_msg = ConversationMessage(
                    user_id=self.user_id,
                    session_id=session_id,
                    role="assistant",
                    content=accumulated_content,
                    message_type="ai_response"
                )
                self.db.add(ai_msg)
                self.db.commit()
            
            # å‘é€å®Œæˆä¿¡å·
            yield {
                "type": "conversation_complete",
                "timestamp": datetime.now(timezone.utc).isoformat()
            }
                
        except Exception as e:
            # è½¬æ¢ä¸ºç”¨æˆ·å‹å¥½çš„é”™è¯¯
            if isinstance(e, AppError):
                app_error = e
            else:
                app_error = translate_error(e)
            
            logger.error("Stream response failed", 
                        user_id=self.user_id,
                        session_id=session_id,
                        error=str(e),
                        error_category=app_error.category.value)
            
            # è¿”å›ç”¨æˆ·å‹å¥½çš„é”™è¯¯ä¿¡æ¯
            error_response = app_error.to_dict()
            error_response['timestamp'] = datetime.now(timezone.utc).isoformat()
            yield error_response
    
    async def _handle_tool_call_chunk(self, tool_chunk):
        """å¤„ç†å•ä¸ªå·¥å…·è°ƒç”¨chunk - åŸºäºçœŸå®çš„LangGraphç»“æ„"""
        
        # ğŸ¯ ç¬¬ä¸€ä¸ªchunkï¼šåŒ…å«å®Œæ•´å·¥å…·ä¿¡æ¯ (name, id, type)
        if tool_chunk.get('name') and tool_chunk.get('id'):
            tool_id = tool_chunk['id']
            tool_name = tool_chunk['name']
            
            # åˆå§‹åŒ–å·¥å…·è°ƒç”¨çŠ¶æ€
            self._active_tool_calls[tool_id] = {
                'name': tool_name,
                'args_fragments': [tool_chunk.get('args', '')],  # å¼€å§‹æ”¶é›†å‚æ•°ç‰‡æ®µ
                'status': 'building_args',
                'start_time': datetime.now(timezone.utc)
            }
            
            logger.debug(f"Tool call started: {tool_name} (ID: {tool_id})", 
                        user_id=self.user_id, tool_name=tool_name, tool_id=tool_id)
            
            # ğŸš€ å‘é€å·¥å…·è°ƒç”¨å¼€å§‹äº‹ä»¶
            yield {
                "type": "tool_call_start",
                "tool_name": tool_name,
                "tool_args": None,  # å‚æ•°è¿˜åœ¨æ„å»ºä¸­
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "id": tool_id
            }
        
        # ğŸ¯ åç»­chunksï¼šç´¯ç§¯å‚æ•°ç‰‡æ®µ (åªæœ‰argså­—æ®µï¼Œnameå’Œidä¸ºNone)
        elif tool_chunk.get('args') is not None:
            # æ‰¾åˆ°å¯¹åº”çš„æ´»è·ƒå·¥å…·è°ƒç”¨ï¼ˆæœ€è¿‘çš„æ­£åœ¨æ„å»ºå‚æ•°çš„è°ƒç”¨ï¼‰
            active_call = None
            for call_id, call_data in self._active_tool_calls.items():
                if call_data['status'] == 'building_args':
                    active_call = (call_id, call_data)
                    break
            
            if active_call:
                call_id, call_data = active_call
                call_data['args_fragments'].append(tool_chunk['args'])
                
                # ğŸ”§ å°è¯•è§£æå®Œæ•´å‚æ•°
                full_args_str = ''.join(call_data['args_fragments'])
                try:
                    args_dict = json.loads(full_args_str)
                    # å‚æ•°æ„å»ºå®Œæˆ
                    call_data['status'] = 'args_complete'
                    call_data['args'] = args_dict
                    
                    logger.debug(f"Tool call args complete: {call_data['name']}", 
                                user_id=self.user_id, tool_args=args_dict, tool_id=call_id)
                    
                    # ğŸ¯ å‘é€å‚æ•°å®Œæ•´äº‹ä»¶
                    yield {
                        "type": "tool_call_args_complete",
                        "tool_name": call_data['name'],
                        "tool_args": args_dict,
                        "timestamp": datetime.now(timezone.utc).isoformat(),
                        "id": call_id
                    }
                except json.JSONDecodeError:
                    # å‚æ•°è¿˜åœ¨æ„å»ºä¸­ï¼Œç»§ç»­ç­‰å¾…
                    logger.debug(f"Tool call args building: {len(full_args_str)} chars", 
                                user_id=self.user_id, args_preview=full_args_str[:100])
                    pass
            else:
                # æ²¡æœ‰æ‰¾åˆ°å¯¹åº”çš„æ´»è·ƒå·¥å…·è°ƒç”¨ï¼Œè®°å½•è­¦å‘Š
                logger.warning("Received tool args chunk but no active tool call found", 
                              user_id=self.user_id, chunk_args=tool_chunk.get('args', '')[:50])

    def _extract_tool_result_from_content(self, content):
        """ä»AIå“åº”å†…å®¹ä¸­æå–å·¥å…·æ‰§è¡Œç»“æœ"""
        try:
            # ğŸ” æ£€æŸ¥æ˜¯å¦æ˜¯JSONæ ¼å¼çš„å·¥å…·ç»“æœ
            if content.strip().startswith('{"status"'):
                # å°è¯•è§£æå·¥å…·ç»“æœJSON
                tool_result = json.loads(content.strip())
                
                # æ‰¾åˆ°å¯¹åº”çš„æ´»è·ƒå·¥å…·è°ƒç”¨
                for call_id, call_data in list(self._active_tool_calls.items()):
                    if call_data['status'] in ['building_args', 'args_complete']:
                        # æ‰¾åˆ°åŒ¹é…çš„å·¥å…·è°ƒç”¨ï¼Œç”Ÿæˆç»“æœäº‹ä»¶
                        call_data['status'] = 'completed'
                        call_data['result'] = tool_result
                        
                        # ğŸ¯ å‘é€å·¥å…·æ‰§è¡Œç»“æœäº‹ä»¶
                        result_event = {
                            "type": "tool_call_result",
                            "tool_name": call_data['name'],
                            "tool_result": tool_result,
                            "timestamp": datetime.now(timezone.utc).isoformat(),
                            "id": call_id
                        }
                        
                        # æ¸…ç†å·²å®Œæˆçš„å·¥å…·è°ƒç”¨
                        del self._active_tool_calls[call_id]
                        
                        logger.debug(f"Tool call completed: {call_data['name']}", 
                                    user_id=self.user_id, tool_id=call_id, 
                                    result_size=len(str(tool_result)))
                        
                        return result_event
                        
        except (json.JSONDecodeError, KeyError, AttributeError) as e:
            # ä¸æ˜¯å·¥å…·ç»“æœï¼Œè¿”å›Noneç»§ç»­ä½œä¸ºæ™®é€šå†…å®¹å¤„ç†
            logger.debug(f"Content is not tool result: {str(e)}", 
                        user_id=self.user_id, content_preview=content[:50])
            pass
        
        return None
    
    
    @classmethod
    def clear_llm_cache(cls):
        """æ¸…ç† LLM ç¼“å­˜ï¼ˆç”¨äºæµ‹è¯•æˆ–å†…å­˜ç®¡ç†ï¼‰"""
        with cls._cache_lock:
            cls._llm_cache.clear()
            logger.info("LLM cache cleared")
    
    @classmethod
    def clear_checkpointer_cache(cls):
        """æ¸…ç† checkpointer ç¼“å­˜"""
        cls._checkpointer_cache.clear()
        logger.info("Checkpointer cache cleared")
    
    @classmethod
    def get_cache_stats(cls) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        with cls._cache_lock:
            llm_stats = {
                "size": len(cls._llm_cache),
                "keys": list(cls._llm_cache.keys()),
                "memory_usage_estimate": f"{len(cls._llm_cache) * 100}MB"  # ç²—ç•¥ä¼°è®¡
            }
        
        # è·å– checkpointer ç¼“å­˜ç»Ÿè®¡ï¼ˆTTLç¼“å­˜è‡ªå¸¦ç»Ÿè®¡æ–¹æ³•ï¼‰
        checkpointer_stats = cls._checkpointer_cache.get_stats()
        
        return {
            "llm_cache": llm_stats,
            "checkpointer_cache": checkpointer_stats
        }
    
    def process(self, message: str) -> str:
        """åŒæ­¥å¤„ç†æ¶ˆæ¯ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰"""
        try:
            import asyncio
            # æ­£ç¡®è°ƒç”¨åŸºç±»çš„å¼‚æ­¥æ–¹æ³•
            return asyncio.run(super().process(message))
        except Exception as e:
            logger.error("Process message failed", 
                        user_id=self.user_id,
                        error=str(e))
            return f"å¤„ç†å¤±è´¥ï¼š{str(e)}"
    
    def get_capabilities(self) -> List[str]:
        """è·å–Agentèƒ½åŠ›åˆ—è¡¨"""
        return [
            "natural_language_understanding",  # è‡ªç„¶è¯­è¨€ç†è§£
            "task_orchestration",             # ä»»åŠ¡ç¼–æ’
            "preference_management",          # åå¥½ç®¡ç†
            "email_search",                   # é‚®ä»¶æœç´¢
            "bulk_operations",                # æ‰¹é‡æ“ä½œ
            "status_tracking",                # çŠ¶æ€è·Ÿè¸ª
            "conversation_management",        # å¯¹è¯ç®¡ç†
            "intelligent_suggestions",       # æ™ºèƒ½å»ºè®®
            "workflow_automation",            # å·¥ä½œæµè‡ªåŠ¨åŒ–
            "context_awareness",              # ä¸Šä¸‹æ–‡æ„ŸçŸ¥
            "streaming_response",             # æµå¼å“åº”
            "tool_visualization"              # å·¥å…·å¯è§†åŒ–
        ]