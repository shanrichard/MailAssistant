# Design 3-2 - ConversationHandler 进一步优化

## Requirements

### 任务背景
基于任务 3-1 已完成的 LangGraph 0.5.3 升级，对 ConversationHandler 进行进一步优化，解决 API 使用细节、线程安全、工具解析等问题。

### 优化需求

1. **API 使用细节修正**
   - 将 `create_react_agent` 的 `state_preprocessor` 参数改为 `prompt` （0.5.3 版本推荐）
   - 修复工具调用事件在 "updates" 模式下的解析结构
   - 清理未使用的 import

2. **LLM 缓存线程安全**
   - 解决高并发时可能同时创建多个相同 key 实例的问题
   - 考虑使用 asyncio.Lock 或 langchain.chat_models.init_chat_model

3. **Checkpointer 优化**
   - 评估是否需要将 InMemorySaver 提升为类级别或外部单例
   - 明确跨会话历史共享策略

4. **自动裁剪历史（可选）**
   - 引入 MessagePrunerNode 限制消息数量，防止超过 token 限制

5. **工具包装一致性**
   - 应用 _safe_tool 包装逻辑到所有工具
   - 统一错误处理返回格式

6. **代码清理**
   - 移除未使用的 import
   - 考虑将系统提示词移到配置文件

## Solution

### 1. API 参数修正

#### 1.1 修改 create_react_agent 参数
```python
# 从：
self.graph_agent = create_react_agent(
    model=self._llm_cache[cache_key],
    tools=self.tools,
    state_preprocessor=self._build_prompt,  # 旧参数
    checkpointer=self.checkpointer
)

# 改为：
self.graph_agent = create_react_agent(
    model=self._llm_cache[cache_key],
    tools=self.tools,
    prompt=self._build_prompt,  # 新参数
    checkpointer=self.checkpointer
)
```

#### 1.2 修复工具调用解析
```python
# 在 stream_response 方法中：
# 处理工具调用 - 适配新的 patch 结构
if "tool" in chunk:
    tool_data = chunk["tool"]
    yield {
        "type": "tool_call_start",
        "tool_name": tool_data.get("name"),
        "tool_args": tool_data.get("args"),
        "timestamp": datetime.now(timezone.utc).isoformat(),
        "id": str(uuid.uuid4())
    }
    if "output" in tool_data:
        yield {
            "type": "tool_call_result",
            "tool_result": tool_data.get("output"),
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "id": str(uuid.uuid4())
        }
```

### 2. LLM 缓存线程安全

```python
import asyncio
from langchain.chat_models import init_chat_model

class ConversationHandler(StatefulAgent):
    _llm_cache = {}
    _cache_lock = asyncio.Lock()
    
    async def _get_or_create_llm(self, cache_key):
        """线程安全的 LLM 实例获取"""
        async with self._cache_lock:
            if cache_key not in self._llm_cache:
                # 使用 init_chat_model 自动管理连接池
                self._llm_cache[cache_key] = init_chat_model(
                    model=cache_key[1],
                    provider=cache_key[0],
                    temperature=cache_key[2]
                )
            return self._llm_cache[cache_key]
```

### 3. Checkpointer 单例化

```python
class ConversationHandler(StatefulAgent):
    # 类级别的 checkpointer
    _checkpointer = None
    
    def __init__(self, user_id: str, db_session, user=None):
        super().__init__(user_id, db_session, user)
        
        # 使用单例 checkpointer
        if self._checkpointer is None:
            self.__class__._checkpointer = InMemorySaver()
        self.checkpointer = self._checkpointer
```

### 4. 添加消息裁剪

```python
from langgraph.graph.modifiers import MessagePrunerNode

def __init__(self, user_id: str, db_session, user=None):
    # ... 其他初始化代码 ...
    
    # 创建带消息裁剪的 agent
    base_agent = create_react_agent(
        model=self._llm_cache[cache_key],
        tools=self.tools,
        prompt=self._build_prompt,
        checkpointer=self.checkpointer
    )
    
    # 添加消息裁剪节点
    graph = StateGraph(AgentState)
    graph.add_node("agent", base_agent)
    graph.add_node("prune", MessagePrunerNode(limit=50))
    graph.add_edge("agent", "prune")
    graph.set_entry_point("agent")
    graph.set_finish_point("prune")
    
    self.graph_agent = graph.compile()
```

### 5. 工具包装改进

```python
def _create_tools(self) -> List[Tool]:
    """创建对话处理工具集，应用统一的错误处理"""
    user_context = {
        "user_id": self.user_id,
        "db_session": self.db,
        "user": self.user
    }
    
    raw_tools = create_conversation_tools(self.user_id, self.db, user_context)
    
    # 应用 _safe_tool 包装
    return [self._wrap_tool_with_error_handling(tool) for tool in raw_tools]

def _wrap_tool_with_error_handling(self, tool: Tool) -> Tool:
    """包装工具，添加统一的错误处理"""
    async def safe_wrapper(*args, **kwargs):
        try:
            return await tool.afunc(*args, **kwargs) if hasattr(tool, 'afunc') else tool.func(*args, **kwargs)
        except Exception as e:
            logger.error(f"Tool {tool.name} failed", error=str(e))
            return {"error": str(e), "tool": tool.name}
    
    return Tool(
        name=tool.name,
        description=tool.description,
        func=safe_wrapper,
        return_direct=False
    )
```

### 6. 代码清理

#### 6.1 移除未使用的 import
```python
# 删除这些行：
# from langgraph.graph import StateGraph, END
# import json
```

#### 6.2 系统提示词外置
```python
# 在 settings.py 中添加：
email_agent_system_prompt = """你是用户的贴心邮件管家..."""

# 在 conversation_handler.py 中：
def _build_system_prompt_for_graph(self) -> str:
    """构建LangGraph使用的系统prompt"""
    return settings.email_agent_system_prompt
```

### 7. 实施步骤

1. **代码修改顺序**
   - 先清理未使用的 import
   - 修改 API 参数（state_preprocessor → prompt）
   - 修复工具调用解析
   - 实现 LLM 缓存线程安全
   - （可选）添加消息裁剪
   - （可选）外置系统提示词

2. **测试计划**
   - 单元测试：验证每个修改点
   - 集成测试：确保前端兼容性
   - 压力测试：验证线程安全和性能

3. **回滚计划**
   - 保留原代码备份
   - 分阶段部署，每个修改点独立验证

## Tests

### 单元测试

1. **test_prompt_parameter**: 验证 prompt 参数正确传递
2. **test_tool_patch_parsing**: 测试新的工具事件解析逻辑
3. **test_llm_cache_thread_safety**: 并发创建 LLM 实例的线程安全测试
4. **test_message_pruning**: 验证消息裁剪功能（如果实现）
5. **test_tool_error_handling**: 测试工具错误处理的一致性

### 集成测试

1. **test_streaming_compatibility**: 确保流式响应格式不变
2. **test_tool_visualization**: 验证工具调用信息正确显示
3. **test_conversation_history**: 测试对话历史管理

### 性能测试

1. **并发测试**: 100 个并发请求下的响应时间
2. **长对话测试**: 200 轮对话后的性能表现
3. **内存测试**: checkpointer 单例化后的内存使用

### 验收标准

- 所有单元测试通过
- 前端无需修改即可正常工作
- 并发性能不低于原版本
- 代码更简洁、可维护性更高