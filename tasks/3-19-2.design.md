# Design 3-19-2 - 后端实现 chunk 累积和批量发送机制

## Requirements

修复 LangGraph messages 模式下过度碎片化的流式响应问题，实现智能的 chunk 累积机制：
1. 累积小的 token-level chunks 到合理大小
2. 根据语义边界（标点符号）智能发送
3. 避免过长等待时间，保持响应实时性
4. 兼容现有的工具调用事件处理

## Solution

### ChunkAccumulator 类设计

创建新文件 `backend/app/utils/chunk_accumulator.py`：

```python
import re
import time
from typing import Optional

class ChunkAccumulator:
    """智能累积流式响应chunks的工具类"""
    
    def __init__(self, 
                 min_chunk_size: int = 10,
                 max_wait_time: float = 0.5,
                 delimiter_pattern: str = r'[。！？；\n]'):
        """
        初始化累积器
        
        Args:
            min_chunk_size: 最小chunk大小（字符数）
            max_wait_time: 最大等待时间（秒）
            delimiter_pattern: 分隔符正则表达式（句子边界）
        """
        self.buffer = ""
        self.last_emit_time = time.time()
        self.min_chunk_size = min_chunk_size
        self.max_wait_time = max_wait_time
        self.delimiter_pattern = delimiter_pattern
    
    def add(self, content: str) -> Optional[str]:
        """添加内容到缓冲区，返回应该发送的内容"""
        self.buffer += content
        
        if self.should_emit():
            return self.flush()
        return None
    
    def should_emit(self) -> bool:
        """判断是否应该发送缓冲内容"""
        # 1. 达到分隔符（句子结束）
        if re.search(self.delimiter_pattern, self.buffer):
            return True
        
        # 2. 缓冲区达到最小大小
        if len(self.buffer) >= self.min_chunk_size:
            return True
        
        # 3. 超过最大等待时间
        if time.time() - self.last_emit_time > self.max_wait_time:
            return True
        
        return False
    
    def flush(self) -> str:
        """清空并返回缓冲区内容"""
        content = self.buffer
        self.buffer = ""
        self.last_emit_time = time.time()
        return content
```

### 修改 ConversationHandler

在 `backend/app/agents/conversation_handler.py` 中集成 ChunkAccumulator：

```python
from app.utils.chunk_accumulator import ChunkAccumulator

async def stream_response(self, state: AgentState, conversation_id: str):
    """流式处理响应，增加智能chunk累积"""
    accumulator = ChunkAccumulator(
        min_chunk_size=self.settings.CHUNK_MIN_SIZE,
        max_wait_time=self.settings.CHUNK_MAX_WAIT,
        delimiter_pattern=self.settings.CHUNK_DELIMITER_PATTERN
    )
    response_id = str(uuid.uuid4())
    accumulated_content = ""  # 用于数据库写入
    
    try:
        async for chunk in self.graph.astream_events(
            state, 
            version="v2",
            stream_mode="messages"
        ):
            # 处理工具调用事件（保持不变）
            if chunk["event"] == "on_tool_start":
                yield self._handle_tool_start(chunk)
            elif chunk["event"] == "on_tool_end":
                yield self._handle_tool_end(chunk)
            
            # 处理消息内容 - 使用累积器
            elif chunk["event"] == "on_chat_model_stream":
                chunk_obj = chunk.get("data", {}).get("chunk")
                if hasattr(chunk_obj, 'content') and chunk_obj.content:
                    # 累积内容
                    emit_content = accumulator.add(chunk_obj.content)
                    accumulated_content += chunk_obj.content
                    
                    if emit_content:
                        yield {
                            "type": "agent_response_chunk",
                            "content": emit_content,
                            "timestamp": datetime.now(timezone.utc).isoformat(),
                            "id": response_id
                        }
        
        # 发送剩余内容
        final_content = accumulator.flush()
        if final_content:
            yield {
                "type": "agent_response_chunk",
                "content": final_content,
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "id": response_id
            }
        
        # 一次性写入完整消息到数据库（任务 3-19-4 会进一步优化）
        if accumulated_content:
            await self._save_message_to_db(
                response_id, 
                conversation_id, 
                accumulated_content
            )
        
        # 发送完成信号
        yield {
            "type": "conversation_complete",
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        logger.error(f"Stream response error: {e}")
        yield {
            "type": "error",
            "message": str(e),
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
```

### 配置支持

在 `backend/app/core/config.py` 中添加：

```python
class Settings(BaseSettings):
    # ... existing settings ...
    
    # Streaming configuration
    CHUNK_MIN_SIZE: int = Field(
        default=10,
        description="Minimum chunk size in characters"
    )
    CHUNK_MAX_WAIT: float = Field(
        default=0.5,
        description="Maximum wait time in seconds"
    )
    CHUNK_DELIMITER_PATTERN: str = Field(
        default=r'[。！？；\n]',
        description="Regex pattern for sentence delimiters"
    )
```

## Tests

### 单元测试

创建 `backend/tests/test_chunk_accumulator.py`：

```python
import pytest
import time
from app.utils.chunk_accumulator import ChunkAccumulator

def test_accumulator_with_delimiter():
    """测试遇到分隔符时立即发送"""
    acc = ChunkAccumulator(min_chunk_size=20)
    
    # 添加不足最小大小的内容
    result = acc.add("你好")
    assert result is None
    
    # 添加包含分隔符的内容
    result = acc.add("，世界。")
    assert result == "你好，世界。"

def test_accumulator_min_size():
    """测试达到最小大小时发送"""
    acc = ChunkAccumulator(min_chunk_size=5)
    
    result = acc.add("一二三")
    assert result is None
    
    result = acc.add("四五")
    assert result == "一二三四五"

def test_accumulator_timeout():
    """测试超时发送"""
    acc = ChunkAccumulator(max_wait_time=0.1)
    
    result = acc.add("测试")
    assert result is None
    
    time.sleep(0.15)
    result = acc.add("内容")
    assert result == "测试内容"

def test_accumulator_flush():
    """测试强制刷新"""
    acc = ChunkAccumulator()
    acc.add("未完成的内容")
    
    result = acc.flush()
    assert result == "未完成的内容"
    assert acc.buffer == ""
```

### 集成测试

创建测试脚本验证端到端流程：

```python
# backend/tests/test_streaming_integration.py
async def test_streaming_with_accumulation():
    """测试累积后的流式响应"""
    # 模拟发送消息并验证响应chunks
    # 确保chunks是按句子或合理大小发送，而非单字符
    pass
```

### 性能基准测试

对比优化前后的性能指标：
- chunk 发送次数
- 数据库写入次数
- 响应延迟
- 内存使用