# Design 3-2-2 - LLM 缓存线程安全改进

## Requirements

### 问题描述
当前 LLM 缓存实现存在并发风险：
- 高并发时可能同时创建多个相同 key 的 LLM 实例
- 缺少线程安全保护机制

### 目标
- 实现线程安全的 LLM 缓存机制
- 防止重复创建 LLM 实例
- 优化内存使用和初始化性能

## Solution

### 1. 添加异步锁保护

```python
import asyncio
from threading import Lock

class ConversationHandler(StatefulAgent):
    """对话处理Agent - 基于LangGraph，支持流式响应和工具调用可视化"""
    
    # 类级别缓存和锁
    _llm_cache = {}
    _cache_lock = Lock()  # 用于同步代码
    _async_cache_lock = None  # 用于异步代码，延迟初始化
```

### 2. 改进 __init__ 方法中的缓存逻辑

```python
def __init__(self, user_id: str, db_session, user=None):
    """初始化ConversationHandler"""
    super().__init__(user_id, db_session, user)
    
    # 创建缓存键
    cache_key = (
        settings.llm.default_provider,
        self._get_default_model(),
        self._get_temperature()
    )
    
    # 线程安全的缓存访问
    with self._cache_lock:
        if cache_key not in self._llm_cache:
            self._llm_cache[cache_key] = self.llm
    
    # 创建 checkpointer
    self.checkpointer = InMemorySaver()
    
    # 使用缓存的 LLM 实例创建 agent
    self.graph_agent = create_react_agent(
        model=self._llm_cache[cache_key],
        tools=self.tools,
        prompt=self._build_prompt,
        checkpointer=self.checkpointer
    )
```

### 3. 为异步场景添加辅助方法（可选）

```python
@classmethod
async def _get_or_create_llm_async(cls, cache_key, llm_factory):
    """异步环境下线程安全的 LLM 实例获取"""
    # 延迟初始化异步锁
    if cls._async_cache_lock is None:
        cls._async_cache_lock = asyncio.Lock()
    
    async with cls._async_cache_lock:
        if cache_key not in cls._llm_cache:
            cls._llm_cache[cache_key] = await llm_factory()
        return cls._llm_cache[cache_key]
```

### 4. 考虑使用 langchain 内置方案（备选）

```python
from langchain.chat_models import init_chat_model

def _create_llm_with_cache(self):
    """使用 langchain 的 init_chat_model（内置连接池）"""
    cache_key = (
        settings.llm.default_provider,
        self._get_default_model(),
        self._get_temperature()
    )
    
    # init_chat_model 内部已经处理了缓存和连接池
    return init_chat_model(
        model=self._get_default_model(),
        model_provider=settings.llm.default_provider,
        temperature=self._get_temperature()
    )
```

### 5. 缓存清理机制（可选）

```python
@classmethod
def clear_llm_cache(cls):
    """清理 LLM 缓存（用于测试或内存管理）"""
    with cls._cache_lock:
        cls._llm_cache.clear()

@classmethod
def get_cache_stats(cls):
    """获取缓存统计信息"""
    with cls._cache_lock:
        return {
            "size": len(cls._llm_cache),
            "keys": list(cls._llm_cache.keys())
        }
```

## Tests

### 单元测试

1. **test_concurrent_initialization**
   ```python
   import concurrent.futures
   
   def test_concurrent_initialization():
       """测试并发初始化时的线程安全"""
       user_ids = [f"user_{i}" for i in range(10)]
       
       def create_handler(user_id):
           return ConversationHandler(user_id, db_session)
       
       with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
           handlers = list(executor.map(create_handler, user_ids))
       
       # 验证缓存中只有一个 LLM 实例
       assert len(ConversationHandler._llm_cache) == 1
   ```

2. **test_cache_key_isolation**
   ```python
   def test_cache_key_isolation():
       """测试不同配置的缓存隔离"""
       # 修改配置创建不同的缓存键
       original_model = settings.agents.conversation_handler_default_model
       
       handler1 = ConversationHandler("user1", db_session)
       
       settings.agents.conversation_handler_default_model = "gpt-4"
       handler2 = ConversationHandler("user2", db_session)
       
       # 验证使用了不同的 LLM 实例
       assert len(ConversationHandler._llm_cache) == 2
       
       # 恢复设置
       settings.agents.conversation_handler_default_model = original_model
   ```

3. **test_cache_cleanup**
   ```python
   def test_cache_cleanup():
       """测试缓存清理功能"""
       handler = ConversationHandler("user", db_session)
       assert len(ConversationHandler._llm_cache) > 0
       
       ConversationHandler.clear_llm_cache()
       assert len(ConversationHandler._llm_cache) == 0
   ```

### 性能测试

1. **test_initialization_performance**
   - 测量有缓存 vs 无缓存的初始化时间差异
   - 验证缓存带来的性能提升

2. **test_memory_usage**
   - 监控多实例创建时的内存使用
   - 确保缓存不会导致内存泄漏

### 压力测试

1. **test_high_concurrency**
   - 模拟 100 个并发请求
   - 验证无死锁、无重复创建

## 验收标准

- [ ] 并发场景下不会创建重复的 LLM 实例
- [ ] 缓存键正确隔离不同配置的实例
- [ ] 性能测试显示缓存有效减少初始化时间
- [ ] 无死锁或竞态条件
- [ ] 代码通过所有并发测试